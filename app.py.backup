import os
import json
import tempfile
import shutil
import subprocess
import base64
import io
import hashlib
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from flask import Flask, render_template, request, jsonify, send_file, make_response
from flask_socketio import SocketIO, emit
from datetime import datetime
from docx import Document
from docx.oxml import OxmlElement
from docx.oxml.ns import qn
import docx.enum.text
from copy import deepcopy
from docxcompose.composer import Composer
from PIL import Image
try:
    from pdf2image import convert_from_path
except:
    convert_from_path = None

try:
    import fitz  # PyMuPDF - szybsza alternatywa do pdf2image
except ImportError:
    fitz = None

# Mutex dla LibreOffice (tylko jedna konwersja naraz)
libreoffice_lock = threading.Lock()

# Mutex dla app4.py/unoserver (tylko jedna konwersja naraz - unoserver single-threaded!)
app4_lock = threading.Lock()

# Cache dla skonwertowanych obraz√≥w (produkty)
conversion_cache = {}

# INTELIGENTNY CACHE dla kompletnych ofert
# Klucz: hash(template_id + form_data + selected_products)
# Warto≈õƒá: {'pages': [lista obraz√≥w], 'total_pages': N, 'timestamp': T}
offer_cache = {}

# Cache dla poszczeg√≥lnych stron (fallback)
page_cache = {}

app = Flask(__name__)
app.config['SECRET_KEY'] = 'secret_key_for_socketio_12345'
app.config['COMPRESS_MIMETYPES'] = ['application/json', 'text/html', 'text/css', 'application/javascript']
app.config['COMPRESS_LEVEL'] = 6
app.config['COMPRESS_MIN_SIZE'] = 500

# W≈ÇƒÖcz kompresjƒô gzip dla wszystkich odpowiedzi
from flask_compress import Compress
Compress(app)

socketio = SocketIO(app, cors_allowed_origins="*")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
TEMPLATES_DIR = os.path.join(BASE_DIR, 'templates')
PRODUKTY_DIR = os.path.join(BASE_DIR, 'produkty')
SAVED_OFFERS_DIR = os.path.join(BASE_DIR, 'saved_offers')
GENERATED_OFFERS_DIR = os.path.join(BASE_DIR, 'generated_offers')
PREVIEW_CACHE_DIR = os.path.join(BASE_DIR, 'static', 'preview_cache')

# Upewnij siƒô, ≈ºe foldery istniejƒÖ
os.makedirs(SAVED_OFFERS_DIR, exist_ok=True)
os.makedirs(GENERATED_OFFERS_DIR, exist_ok=True)
os.makedirs(PREVIEW_CACHE_DIR, exist_ok=True)


def preload_all_products():
    """Pre-generuje wszystkie produkty przy starcie aplikacji"""
    print("[STARTUP] Pre-generowanie produkt√≥w...")

    if not os.path.exists(PRODUKTY_DIR):
        print("[STARTUP] Folder produkt√≥w nie istnieje")
        return

    product_files = [f for f in os.listdir(PRODUKTY_DIR) if f.endswith('.docx')]
    total = len(product_files)

    print(f"[STARTUP] Znaleziono {total} produkt√≥w do pre-generowania")

    for idx, filename in enumerate(product_files):
        product_path = os.path.join(PRODUKTY_DIR, filename)
        print(f"[STARTUP] Pre-generujƒô {idx+1}/{total}: {filename}")

        try:
            # Konwertuj z cache - przy pierwszym uruchomieniu wype≈Çni cache
            convert_docx_to_images(product_path, use_cache=True)
            print(f"[STARTUP] ‚úì {filename} gotowy")
        except Exception as e:
            print(f"[STARTUP] ‚úó B≈ÇƒÖd dla {filename}: {e}")

    print(f"[STARTUP] Pre-generowanie zako≈Ñczone! Cache zawiera {len(conversion_cache)} produkt√≥w")


def preload_all_templates():
    """
    NOWA STRATEGIA - NIE RENDERUJ czystych szablon√≥w!

    Dlaczego?
    - Czysty szablon ma {{placeholders}} - i tak trzeba bƒôdzie go re-renderowaƒá
    - To STRATA CZASU przy starcie
    - Lepiej renderowaƒá ON-DEMAND z prawdziwymi danymi

    Co robimy zamiast tego:
    - Pre-renderujemy tylko PRODUKTY (nie zmieniajƒÖ siƒô)
    - Cache tworzymy PODCZAS pierwszego u≈ºycia (z prawdziwymi danymi)
    """
    print("=" * 80)
    print("[STARTUP] üí° INTELIGENTNY SYSTEM CACHE")
    print("=" * 80)
    print("[STARTUP] ‚ÑπÔ∏è  Szablony bƒôdƒÖ renderowane ON-DEMAND (szybsze!)")
    print("[STARTUP] ‚ÑπÔ∏è  Produkty sƒÖ pre-renderowane (gotowe do u≈ºycia)")
    print("=" * 80)

    # Inicjalizuj pusty cache - wype≈Çni siƒô podczas u≈ºytkowania
    # Klucz: hash(template_id + form_data + products)
    # Warto≈õƒá: [lista obraz√≥w base64]


# Pre-generuj produkty przy starcie (w tle, nie blokuj startu)
def preload_products_async():
    """Uruchom pre-generowanie w osobnym wƒÖtku"""
    import threading
    thread = threading.Thread(target=preload_all_products, daemon=True)
    thread.start()

def preload_templates_async():
    """Uruchom pre-generowanie szablon√≥w w osobnym wƒÖtku"""
    import threading
    thread = threading.Thread(target=preload_all_templates, daemon=True)
    thread.start()

def get_file_hash(filepath):
    """Oblicza hash pliku dla cache"""
    try:
        with open(filepath, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()
    except:
        return None


def get_form_data_hash(form_data):
    """Oblicza hash danych formularza dla cache szablonu"""
    try:
        # Sortuj klucze dla stabilnego hasha
        sorted_data = json.dumps(form_data, sort_keys=True)
        return hashlib.md5(sorted_data.encode('utf-8')).hexdigest()
    except:
        return None


def get_offer_cache_key(template_id, form_data, selected_products, product_custom_fields):
    """
    Generuje unikalny klucz cache dla kompletnej oferty

    Klucz uwzglƒôdnia:
    - template_id (aidrops/wolftax)
    - form_data (dane formularza - placeholders)
    - selected_products (lista ID produkt√≥w)
    - product_custom_fields (custom pola produkt√≥w)

    Returns: string (hash MD5)
    """
    try:
        cache_key_data = {
            'template_id': template_id,
            'form_data': form_data,
            'selected_products': sorted(selected_products),  # sort dla stabilno≈õci
            'product_custom_fields': product_custom_fields
        }
        cache_key_json = json.dumps(cache_key_data, sort_keys=True)
        cache_key_hash = hashlib.md5(cache_key_json.encode('utf-8')).hexdigest()
        return cache_key_hash
    except Exception as e:
        print(f"[CACHE] ‚ùå B≈ÇƒÖd generowania klucza: {e}")
        return None


def send_progress(message, percent):
    """Wysy≈Ça progress przez WebSocket"""
    try:
        socketio.emit('conversion_progress', {
            'message': message,
            'percent': percent
        })
    except:
        pass  # Ignoruj b≈Çƒôdy WebSocket


def send_page_ready(page_data):
    """Wysy≈Ça gotowƒÖ stronƒô przez WebSocket (streaming)"""
    try:
        socketio.emit('page_ready', page_data)
        print(f"[DEBUG] ‚úì Wys≈Çano stronƒô {page_data.get('number')} przez WebSocket")
    except Exception as e:
        print(f"[ERROR] B≈ÇƒÖd wysy≈Çania strony: {e}")


def check_unoserver_running():
    """Sprawdza czy unoserver jest uruchomiony"""
    try:
        result = subprocess.run(['pgrep', '-f', 'unoserver'], capture_output=True, text=True)
        return result.returncode == 0
    except:
        return False


def start_unoserver():
    """Uruchamia unoserver w trybie daemon je≈õli nie jest uruchomiony"""
    if check_unoserver_running():
        print("[UNOSERVER] ‚úì Unoserver ju≈º dzia≈Ça")
        return True

    print("[UNOSERVER] Uruchamiam unoserver --daemon...")
    try:
        # Uruchom unoserver w tle
        subprocess.Popen(
            ['unoserver', '--daemon'],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            start_new_session=True
        )

        # Poczekaj chwilƒô na start
        import time
        time.sleep(2)

        if check_unoserver_running():
            print("[UNOSERVER] ‚úì Unoserver uruchomiony pomy≈õlnie")
            return True
        else:
            print("[UNOSERVER] ‚ùå Nie uda≈Ço siƒô uruchomiƒá unoserver")
            return False
    except FileNotFoundError:
        print("[UNOSERVER] ‚ùå Nie znaleziono unoserver w PATH")
        return False
    except Exception as e:
        print(f"[UNOSERVER] ‚ùå B≈ÇƒÖd uruchamiania: {e}")
        return False


def convert_docx_to_images_unoserver(docx_path, dpi=200, quality=90, uc_host='127.0.0.1', uc_port=2003):
    """
    SUPER FAST DOCX ‚Üí JPG u≈ºywajƒÖc app4.py!
    Wywo≈Çuje: python app4.py DOCX -o OUT --dpi DPI --quality Q --uc-host H --uc-port P

    WA≈ªNE: Unoserver obs≈Çuguje tylko 1 konwersjƒô naraz - u≈ºywamy mutex!
    """
    print(f"[APP4] Czekam na dostƒôp do unoserver...")

    # MUTEX - tylko jedna konwersja app4.py/unoserver naraz!
    with app4_lock:
        print(f"[APP4] üöÄ START: {os.path.basename(docx_path)}")

        # Sprawd≈∫ czy app4.py istnieje
        app4_path = os.path.join(BASE_DIR, 'app4.py')
        if not os.path.exists(app4_path):
            print(f"[APP4] ‚ùå Brak app4.py w {BASE_DIR}")
            return None

        # Tymczasowy katalog na JPG
        temp_outdir = tempfile.mkdtemp(dir=PREVIEW_CACHE_DIR)

        try:
            # Wywo≈Çaj app4.py DOK≈ÅADNIE jak w przyk≈Çadzie!
            cmd = [
                'python',
                app4_path,
                docx_path,
                '-o', temp_outdir,
                '--dpi', str(dpi),
                '--quality', str(quality),
                '--uc-host', uc_host,
                '--uc-port', str(uc_port)
            ]

            print(f"[APP4] Cmd: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=30  # 30s timeout - du≈ºo czasu dla du≈ºych plik√≥w
            )

            if result.returncode != 0:
                print(f"[APP4] ‚ùå Failed:")
                print(f"[APP4] stdout: {result.stdout[:300]}")
                print(f"[APP4] stderr: {result.stderr[:300]}")
                return None

            print(f"[APP4] stdout: {result.stdout.strip()}")

            # Zbierz wygenerowane JPG
            jpg_files = sorted([
                f for f in os.listdir(temp_outdir)
                if f.lower().endswith(('.jpg', '.jpeg'))
            ])

            if not jpg_files:
                print(f"[APP4] ‚ùå Brak plik√≥w JPG w {temp_outdir}")
                return None

            print(f"[APP4] ‚úì Znaleziono {len(jpg_files)} plik√≥w JPG")

            # Wczytaj JPG i konwertuj na base64
            image_data_list = []
            for jpg_file in jpg_files:
                jpg_path = os.path.join(temp_outdir, jpg_file)
                with open(jpg_path, 'rb') as f:
                    jpg_bytes = f.read()
                    img_base64 = base64.b64encode(jpg_bytes).decode('utf-8')
                    image_data_list.append(f"data:image/jpeg;base64,{img_base64}")

            print(f"[APP4] ‚úì SUPER FAST: {len(image_data_list)} stron")
            return image_data_list

        except subprocess.TimeoutExpired:
            print("[APP4] ‚ùå Timeout (>30s)")
            return None
        except FileNotFoundError as e:
            print(f"[APP4] ‚ùå File not found: {e}")
            return None
        except Exception as e:
            print(f"[APP4] ‚ùå Error: {e}")
            import traceback
            traceback.print_exc()
            return None
        finally:
            # Cleanup
            try:
                shutil.rmtree(temp_outdir)
            except:
                pass


def convert_docx_to_images(docx_path, use_cache=True, progress_callback=None):
    """
    Konwertuje plik DOCX na obrazy JPEG (1:1 wyglƒÖd)
    Zwraca listƒô ≈õcie≈ºek do obraz√≥w (base64 encoded)

    Strategia:
    1. Sprawd≈∫ cache
    2. Spr√≥buj unoserver (szybkie!)
    3. Fallback: LibreOffice + pdf2image
    """
    try:
        # Sprawd≈∫ cache
        if use_cache:
            file_hash = get_file_hash(docx_path)
            if file_hash and file_hash in conversion_cache:
                print(f"[CACHE] ‚ö° U≈ºywam cache dla: {docx_path}")
                return conversion_cache[file_hash]

        print(f"[CONVERT] Rozpoczynam konwersjƒô: {docx_path}")

        # ===== SPR√ìBUJ APP4.PY (SUPER FAST!) =====
        if check_unoserver_running():
            print(f"[CONVERT] üöÄ U≈ºywam app4.py (SUPER FAST)...")
            if progress_callback:
                progress_callback("‚ö° SUPER FAST conversion (app4.py)...", 20)

            images = convert_docx_to_images_unoserver(docx_path, dpi=200, quality=90)

            if images:
                # SUKCES! Zapisz do cache
                if use_cache:
                    file_hash = get_file_hash(docx_path)
                    if file_hash:
                        conversion_cache[file_hash] = images
                print(f"[CONVERT] ‚úì APP4: {len(images)} stron")
                return images
            else:
                print(f"[CONVERT] ‚ö†Ô∏è APP4 failed, fallback do LibreOffice...")

        # ===== FALLBACK: LIBREOFFICE + pdf2image =====
        print(f"[CONVERT] Fallback: LibreOffice + pdf2image")

        # Najpierw konwertuj DOCX na PDF u≈ºywajƒÖc LibreOffice/soffice
        pdf_path = docx_path.replace('.docx', '.pdf')

        # Sprawd≈∫ czy LibreOffice jest dostƒôpne
        soffice_paths = [
            '/Applications/LibreOffice.app/Contents/MacOS/soffice',
            '/usr/local/bin/soffice',
            'soffice'
        ]

        soffice_path = None
        for path in soffice_paths:
            if os.path.exists(path) or path == 'soffice':
                soffice_path = path
                print(f"[DEBUG] Znaleziono LibreOffice: {path}")
                break

        if not soffice_path:
            print("[ERROR] LibreOffice nie znalezione!")
            return []

        # MUTEX - tylko jedna konwersja LibreOffice naraz
        with libreoffice_lock:
            try:
                # Konwersja DOCX ‚Üí PDF
                print(f"[DEBUG] Konwertujƒô DOCX ‚Üí PDF: {docx_path}")
                if progress_callback:
                    progress_callback("Konwersja do PDF...", 20)

                result = subprocess.run([
                    soffice_path,
                    '--headless',
                    '--convert-to', 'pdf',
                    '--outdir', os.path.dirname(docx_path),
                    docx_path
                ], check=True, capture_output=True, timeout=60)  # Zwiƒôkszono timeout do 60s

                print(f"[DEBUG] LibreOffice stdout: {result.stdout.decode('utf-8', errors='ignore')}")
                print(f"[DEBUG] LibreOffice stderr: {result.stderr.decode('utf-8', errors='ignore')}")

            except subprocess.CalledProcessError as e:
                print(f"[ERROR] LibreOffice b≈ÇƒÖd: {e}")
                print(f"[ERROR] stdout: {e.stdout.decode('utf-8', errors='ignore')}")
                print(f"[ERROR] stderr: {e.stderr.decode('utf-8', errors='ignore')}")
                return []
            except FileNotFoundError:
                print(f"[ERROR] Nie znaleziono pliku: {soffice_path}")
                return []
            except subprocess.TimeoutExpired:
                print("[ERROR] Timeout podczas konwersji LibreOffice")
                return []

        # Sprawd≈∫ czy PDF zosta≈Ç utworzony
        if not os.path.exists(pdf_path):
            print(f"[ERROR] PDF nie zosta≈Ç utworzony: {pdf_path}")
            return []

        print(f"[DEBUG] PDF utworzony: {pdf_path}")

        # Konwertuj PDF na obrazy PNG
        if not convert_from_path:
            print("[ERROR] pdf2image nie jest zainstalowane!")
            return []

        try:
            print(f"[DEBUG] Konwertujƒô PDF ‚Üí PNG")
            if progress_callback:
                progress_callback("Konwersja PDF na obrazy...", 30)

            images = convert_from_path(pdf_path, dpi=100)  # Zmniejszono z 150 na 100 dla szybko≈õci
            print(f"[DEBUG] Wygenerowano {len(images)} stron")

            image_data_list = []
            for i, image in enumerate(images):
                # Progress: Konwersja stron
                if progress_callback and len(images) > 1:
                    page_progress = 30 + int(10 * ((i + 1) / len(images)))
                    progress_callback(f"Przetwarzam stronƒô {i+1}/{len(images)}...", page_progress)

                # Optymalizuj obraz przed konwersjƒÖ do base64
                # 1. Konwertuj do RGB (usunƒÖƒá alpha channel je≈õli nie potrzebny)
                if image.mode == 'RGBA':
                    # Tylko konwertuj je≈õli nie ma transparentno≈õci
                    background = Image.new('RGB', image.size, (255, 255, 255))
                    background.paste(image, mask=image.split()[3])  # 3 to alpha channel
                    image = background

                # 2. Zapisz jako JPEG z kompresjƒÖ dla mniejszego rozmiaru
                # JPEG jest ~70% mniejszy ni≈º PNG przy zachowaniu dobrej jako≈õci
                buffered = io.BytesIO()
                image.save(buffered, format="JPEG", quality=85, optimize=True)
                img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
                image_data_list.append(f"data:image/jpeg;base64,{img_base64}")
                print(f"[DEBUG] Strona {i+1} skonwertowana (rozmiar: {len(img_base64)} znak√≥w, format: JPEG)")

            # Usu≈Ñ tymczasowy PDF
            try:
                os.remove(pdf_path)
                print(f"[DEBUG] Usuniƒôto tymczasowy PDF")
            except:
                pass

            # Zapisz w cache
            if use_cache and file_hash:
                conversion_cache[file_hash] = image_data_list
                print(f"[DEBUG] Zapisano w cache: {docx_path}")

            return image_data_list

        except Exception as e:
            print(f"[ERROR] B≈ÇƒÖd konwersji PDF ‚Üí PNG: {e}")
            import traceback
            traceback.print_exc()
            return []

    except Exception as e:
        print(f"[ERROR] Og√≥lny b≈ÇƒÖd konwersji DOCX na obrazy: {e}")
        import traceback
        traceback.print_exc()
        return []


def load_template_config(template_name='oferta1'):
    """Wczytuje konfiguracjƒô szablonu z pliku JSON"""
    config_path = os.path.join(TEMPLATES_DIR, f'{template_name}.json')
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def extract_placeholders_from_docx(docx_path):
    """
    WyciƒÖga wszystkie {{placeholders}} z pliku DOCX
    Zwraca set z nazwami placeholders
    """
    import re
    try:
        doc = Document(docx_path)
        placeholders = set()

        # Szukaj w paragrafach
        for para in doc.paragraphs:
            matches = re.findall(r'\{\{([^}]+)\}\}', para.text)
            placeholders.update(matches)

        # Szukaj w tabelach
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    matches = re.findall(r'\{\{([^}]+)\}\}', cell.text)
                    placeholders.update(matches)

        return placeholders
    except Exception as e:
        print(f"[ERROR] B≈ÇƒÖd wyciƒÖgania placeholders z {docx_path}: {e}")
        return set()


def generate_table_of_contents(selected_products, product_custom_fields, start_page=5):
    """
    Generuje spis tre≈õci dla WolfTax w formacie:
    ¬ß	Us≈Çuga 1 ‚Äì Nazwa us≈Çugi ‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶‚Ä¶  05
    """
    toc_lines = []
    current_page = start_page

    for idx, product_id in enumerate(selected_products, 1):
        # Pobierz tytu≈Ç z custom fields lub u≈ºyj domy≈õlnej nazwy
        product_data = product_custom_fields.get(product_id, {})
        title = product_data.get('title') or product_data.get('nazwa') or product_data.get('nazwa_uslugi') or f'Produkt {product_id}'

        # Oblicz liczbƒô kropek (dots) dla wyr√≥wnania
        # Format: "¬ß\tUs≈Çuga 1 ‚Äì {title} ‚Ä¶‚Ä¶‚Ä¶‚Ä¶.‚Ä¶‚Ä¶  {page}"
        base_text = f"Us≈Çuga {idx} ‚Äì {title}"
        dots_count = max(60 - len(base_text), 10)  # Minimum 10 kropek
        dots = '‚Ä¶' * dots_count

        line = f"¬ß\t{base_text} {dots}  {current_page:02d}"
        toc_lines.append(line)

        # Policz strony produktu (zak≈Çadam 1-2 strony na produkt, mo≈ºna to poprawiƒá)
        # TODO: Mo≈ºesz dodaƒá logikƒô zliczania stron z conversion_cache
        product_path = os.path.join(PRODUKTY_DIR, f'{product_id}.docx')
        file_hash = get_file_hash(product_path)
        if file_hash and file_hash in conversion_cache:
            product_pages = len(conversion_cache[file_hash])
        else:
            product_pages = 1  # Domy≈õlnie 1 strona

        current_page += product_pages

    return '\n'.join(toc_lines)


def inject_toc_into_doc(doc, toc_text):
    """
    Wstawia spis tre≈õci do dokumentu DOCX
    Szuka {{SPIS_TRESCI}} lub {{TOC}} i zastƒôpuje tekstem
    """
    injected = False

    for para in doc.paragraphs:
        if '{{SPIS_TRESCI}}' in para.text or '{{TOC}}' in para.text:
            para.text = para.text.replace('{{SPIS_TRESCI}}', toc_text)
            para.text = para.text.replace('{{TOC}}', toc_text)
            injected = True
            print(f"[TOC] Wstawiono spis tre≈õci (zastƒÖpiono placeholder)")
            break

    # Je≈õli nie ma placeholdera, dodaj na ko≈Ñcu
    if not injected:
        print(f"[TOC] Brak placeholdera - dodajƒô na ko≈Ñcu dokumentu")
        doc.add_paragraph(toc_text)

    return doc


def get_available_products():
    """Pobiera listƒô dostƒôpnych produkt√≥w z folderu produkty + wykrywa {{placeholders}}"""
    products = []
    if os.path.exists(PRODUKTY_DIR):
        for filename in sorted(os.listdir(PRODUKTY_DIR)):
            if filename.endswith('.docx') and not filename.startswith('~$'):
                product_id = filename.replace('.docx', '')
                product_path = os.path.join(PRODUKTY_DIR, filename)

                # Wykryj placeholders w produkcie
                placeholders = extract_placeholders_from_docx(product_path)

                products.append({
                    'id': product_id,
                    'name': f'Produkt {product_id}',
                    'filename': filename,
                    'placeholders': list(placeholders),  # Konwertuj set na list dla JSON
                    'has_custom_fields': len(placeholders) > 0
                })
    return products


def replace_placeholders(doc, data):
    """Zamienia placeholdery w dokumencie na rzeczywiste dane"""
    # Zamiana w paragrafach
    for paragraph in doc.paragraphs:
        for key, value in data.items():
            if key != 'produkty':  # Produkty obs≈Çugujemy osobno
                placeholder = '{{' + key + '}}'
                if placeholder in paragraph.text:
                    paragraph.text = paragraph.text.replace(placeholder, str(value))

    # Zamiana w tabelach
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for key, value in data.items():
                    if key != 'produkty':
                        placeholder = '{{' + key + '}}'
                        if placeholder in cell.text:
                            cell.text = cell.text.replace(placeholder, str(value))

    return doc


def find_injection_point(doc, search_text):
    """Znajduje punkt wstrzykniƒôcia produkt√≥w w dokumencie"""
    for i, paragraph in enumerate(doc.paragraphs):
        # Usu≈Ñ placeholder z tekstu szukanego
        clean_search = search_text.replace('{{opis}}', '')
        if clean_search.strip() in paragraph.text:
            return i
    return None


def insert_page_break(paragraph):
    """Dodaje page break przed paragrafem"""
    run = paragraph.insert_paragraph_before().add_run()
    run.add_break(docx.enum.text.WD_BREAK.PAGE)


def split_document_at_injection_point(template_path, injection_index, data):
    """Dzieli szablon na dwie czƒô≈õci: przed i po punkcie wstrzykniƒôcia

    UWAGA: W wiƒôkszo≈õci przypadk√≥w strona 1 to WSZYSTKO przed page break,
    wiƒôc part2 zazwyczaj bƒôdzie None (brak strony 2 w szablonie)
    """

    # Wczytaj szablon z zamienionymi placeholderami
    doc = Document(template_path)
    doc = replace_placeholders(doc, data)

    # Sprawd≈∫ czy w szablonie sƒÖ wyra≈∫ne page breaks (section breaks)
    has_explicit_page_break = False
    page_break_at_section = -1

    for i, section in enumerate(doc.sections):
        if i > 0:  # Jest wiƒôcej ni≈º jedna sekcja - znaczy ≈ºe jest page break
            has_explicit_page_break = True
            page_break_at_section = i
            break

    if has_explicit_page_break:
        # Szablon ma wyra≈∫ny podzia≈Ç na sekcje (strony)
        # Part1 = pierwsza sekcja, Part2 = reszta
        part1_doc = Document(template_path)
        part1_doc = replace_placeholders(part1_doc, data)

        # TODO: Zaimplementuj podzia≈Ç wed≈Çug sekcji
        # Na razie zwr√≥ƒá ca≈Çy dokument jako part1
        part2_doc = None
    else:
        # Szablon NIE ma wyra≈∫nego podzia≈Çu
        # WSZYSTKO jest stronƒÖ 1, part2 nie istnieje
        part1_doc = Document(template_path)
        part1_doc = replace_placeholders(part1_doc, data)
        part2_doc = None

    return part1_doc, part2_doc


def add_page_break_to_doc(doc):
    """Dodaje page break na ko≈Ñcu dokumentu"""
    # Dodaj prosty page break na ko≈Ñcu
    paragraph = doc.add_paragraph()
    run = paragraph.add_run()
    run.add_break(docx.enum.text.WD_BREAK.PAGE)
    return doc


def generate_multifile_offer_docx(data, selected_products, template_data):
    """Generuje ofertƒô DOCX dla multi-file template (WolfTax)"""
    print(f"[MULTIFILE DOCX] Generujƒô ofertƒô z {len(template_data['files'])} plik√≥w")

    form_data = data.get('formData', data)  # Kompatybilno≈õƒá
    product_custom_fields = data.get('productCustomFields', {})

    template_folder = os.path.join(TEMPLATES_DIR, template_data['folder'])
    files = sorted(template_data['files'], key=lambda x: x['order'])
    injection_point = template_data.get('injection_point', {})

    # Zacznij od pustego dokumentu
    first_file_path = os.path.join(template_folder, files[0]['file'])
    first_doc = Document(first_file_path)
    first_doc = replace_placeholders(first_doc, form_data)

    composer = Composer(first_doc)

    # Przetw√≥rz pozosta≈Çe pliki
    for file_info in files[1:]:
        file_path = os.path.join(template_folder, file_info['file'])

        if not os.path.exists(file_path):
            continue

        doc = Document(file_path)
        doc = replace_placeholders(doc, form_data)

        # SPIS TRE≈öCI
        if file_info.get('is_toc') and len(selected_products) > 0:
            toc_config = template_data.get('toc', {})
            start_page = toc_config.get('start_page', 5)
            toc_text = generate_table_of_contents(selected_products, product_custom_fields, start_page)
            doc = inject_toc_into_doc(doc, toc_text)
            print(f"[TOC DOCX] Spis tre≈õci dodany")

        # INJECTION POINT - produkty
        if (injection_point.get('type') == 'between_files' and
            file_info['file'] == injection_point.get('after')):

            # Najpierw dodaj ten dokument
            composer.append(doc, restart_numbering=True)

            # Wstaw produkty
            print(f"[MULTIFILE DOCX] Wstawiam {len(selected_products)} produkt√≥w")
            for product_id in selected_products:
                product_path = os.path.join(PRODUKTY_DIR, f'{product_id}.docx')
                if os.path.exists(product_path):
                    product_doc = Document(product_path)

                    # Custom fields
                    if product_id in product_custom_fields:
                        custom_data = product_custom_fields[product_id]
                        product_doc = replace_placeholders(product_doc, custom_data)

                    product_doc = add_page_break_to_doc(product_doc)
                    composer.append(product_doc, restart_numbering=True)

            continue  # Ju≈º dodany

        # Normalnie dodaj dokument
        composer.append(doc, restart_numbering=True)

    # Zapisz
    client_name = form_data.get('KLIENT(NIP)') or form_data.get('klient') or 'Klient'
    output_filename = f"Oferta_WolfTax_{client_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx"
    output_path = os.path.join(GENERATED_OFFERS_DIR, output_filename)

    composer.save(output_path)
    print(f"[MULTIFILE DOCX] Zapisano: {output_filename}")

    return output_path, output_filename


def generate_offer_docx(data, selected_products, template_data=None):
    """Generuje dokument DOCX oferty - MULTI-TEMPLATE SUPPORT"""

    # Sprawd≈∫ czy to multi-file czy single-file
    if template_data and template_data.get('type') == 'multi_file':
        return generate_multifile_offer_docx(data, selected_products, template_data)

    # STARY SYSTEM - AIDROPS
    template_config = load_template_config('oferta1')
    template_path = os.path.join(TEMPLATES_DIR, template_config['template_file'])

    # Znajd≈∫ punkt wstrzykniƒôcia
    injection_config = template_config.get('injection_point', {})
    injection_text = injection_config.get('after_paragraph_containing', '')

    # Wczytaj szablon tymczasowo aby znale≈∫ƒá injection point
    temp_doc = Document(template_path)
    temp_doc = replace_placeholders(temp_doc, data)
    injection_index = find_injection_point(temp_doc, injection_text)

    if injection_index is None:
        # Je≈õli nie znaleziono punktu wstrzykniƒôcia, u≈ºyj prostego podej≈õcia
        main_doc = Document(template_path)
        main_doc = replace_placeholders(main_doc, data)

        if selected_products:
            # Dodaj page break na ko≈Ñcu pierwszej strony
            main_doc = add_page_break_to_doc(main_doc)

            composer = Composer(main_doc)
            for product_id in selected_products:
                product_path = os.path.join(PRODUKTY_DIR, f'{product_id}.docx')
                if os.path.exists(product_path):
                    product_doc = Document(product_path)
                    # Dodaj page break na ko≈Ñcu ka≈ºdego produktu
                    product_doc = add_page_break_to_doc(product_doc)
                    # WA≈ªNE: restart_numbering=True aby produkt by≈Ç niezale≈ºny
                    composer.append(product_doc, restart_numbering=True)
        else:
            composer = Composer(main_doc)
    else:
        # Podziel szablon na czƒô≈õci
        part1_doc, part2_doc = split_document_at_injection_point(template_path, injection_index, data)

        # Dodaj page break na ko≈Ñcu part1
        part1_doc = add_page_break_to_doc(part1_doc)

        # Rozpocznij od pierwszej czƒô≈õci
        composer = Composer(part1_doc)

        # Dodaj wszystkie produkty JAKO NIEZALE≈ªNE DOKUMENTY
        for product_id in selected_products:
            product_path = os.path.join(PRODUKTY_DIR, f'{product_id}.docx')
            if os.path.exists(product_path):
                product_doc = Document(product_path)

                # CUSTOM FIELDS: Je≈õli produkt ma custom fields, podstaw warto≈õci
                if product_id in data.get('productCustomFields', {}):
                    custom_data = data['productCustomFields'][product_id]
                    print(f"[DEBUG] Podstawiam custom fields dla produktu {product_id}: {custom_data}")
                    product_doc = replace_placeholders(product_doc, custom_data)

                # Dodaj page break na ko≈Ñcu ka≈ºdego produktu
                product_doc = add_page_break_to_doc(product_doc)
                # WA≈ªNE: restart_numbering=True aby ka≈ºdy produkt zachowa≈Ç swojƒÖ sekcjƒô
                composer.append(product_doc, restart_numbering=True)

        # Dodaj drugƒÖ czƒô≈õƒá (je≈õli istnieje)
        if part2_doc:
            composer.append(part2_doc)

    # Zapisz dokument
    output_filename = f"Oferta_{data.get('KLIENT(NIP)', 'Klient')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx"
    output_path = os.path.join(GENERATED_OFFERS_DIR, output_filename)

    composer.save(output_path)

    return output_path, output_filename


@app.route('/')
def index():
    """G≈Ç√≥wna strona aplikacji"""
    response = make_response(render_template('index.html'))
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
    return response


@app.route('/api/templates')
def get_templates():
    """Zwraca listƒô dostƒôpnych szablon√≥w"""
    templates_config_path = os.path.join(TEMPLATES_DIR, 'templates.json')

    with open(templates_config_path, 'r', encoding='utf-8') as f:
        templates_data = json.load(f)

    return jsonify(templates_data)


@app.route('/api/template/<template_id>')
def get_template_details(template_id):
    """Zwraca szczeg√≥≈Çy szablonu + wykrywa wszystkie {{placeholders}}"""
    templates_config_path = os.path.join(TEMPLATES_DIR, 'templates.json')

    with open(templates_config_path, 'r', encoding='utf-8') as f:
        templates_data = json.load(f)

    # Znajd≈∫ szablon
    template = None
    for t in templates_data['templates']:
        if t['id'] == template_id:
            template = t
            break

    if not template:
        return jsonify({'error': 'Szablon nie znaleziony'}), 404

    # Skanuj wszystkie pliki i zbierz placeholders
    all_placeholders = {}

    if template['type'] == 'single_file':
        # Stary system - pojedynczy plik
        file_path = os.path.join(TEMPLATES_DIR, template.get('folder', '.'), template['main_file'])
        placeholders = extract_placeholders_from_docx(file_path)
        all_placeholders['main'] = list(placeholders)

    elif template['type'] == 'multi_file':
        # Nowy system - wiele plik√≥w
        template_folder = os.path.join(TEMPLATES_DIR, template['folder'])

        for file_info in template['files']:
            file_path = os.path.join(template_folder, file_info['file'])
            if os.path.exists(file_path):
                placeholders = extract_placeholders_from_docx(file_path)
                if placeholders:
                    all_placeholders[file_info['file']] = {
                        'name': file_info.get('name', file_info['file']),
                        'placeholders': list(placeholders)
                    }

    template['discovered_placeholders'] = all_placeholders
    template['total_placeholders'] = sum(
        len(v['placeholders']) if isinstance(v, dict) else len(v)
        for v in all_placeholders.values()
    )

    return jsonify(template)


@app.route('/api/template-config')
def get_template_config():
    """Zwraca konfiguracjƒô szablonu (legacy compatibility)"""
    config = load_template_config('oferta1')
    return jsonify(config)


@app.route('/api/products')
def get_products():
    """Zwraca listƒô dostƒôpnych produkt√≥w"""
    products = get_available_products()
    return jsonify(products)


@app.route('/api/save-offer', methods=['POST'])
def save_offer():
    """Zapisuje ofertƒô do pliku JSON"""
    data = request.json
    offer_name = data.get('offer_name', f"oferta_{datetime.now().strftime('%Y%m%d_%H%M%S')}")

    # Usu≈Ñ offer_name z danych do zapisu
    offer_data = {k: v for k, v in data.items() if k != 'offer_name'}

    filename = f"{offer_name}.json"
    filepath = os.path.join(SAVED_OFFERS_DIR, filename)

    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(offer_data, f, ensure_ascii=False, indent=2)

    return jsonify({'success': True, 'filename': filename})


@app.route('/api/load-offer/<filename>')
def load_offer(filename):
    """Wczytuje zapisanƒÖ ofertƒô"""
    filepath = os.path.join(SAVED_OFFERS_DIR, filename)

    if not os.path.exists(filepath):
        return jsonify({'error': 'Plik nie istnieje'}), 404

    with open(filepath, 'r', encoding='utf-8') as f:
        data = json.load(f)

    return jsonify(data)


@app.route('/api/saved-offers')
def get_saved_offers():
    """Zwraca listƒô zapisanych ofert"""
    offers = []
    if os.path.exists(SAVED_OFFERS_DIR):
        for filename in os.listdir(SAVED_OFFERS_DIR):
            if filename.endswith('.json'):
                filepath = os.path.join(SAVED_OFFERS_DIR, filename)
                stat = os.stat(filepath)
                offers.append({
                    'filename': filename,
                    'name': filename.replace('.json', ''),
                    'modified': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
                })

    # Sortuj po dacie modyfikacji (najnowsze pierwsze)
    offers.sort(key=lambda x: x['modified'], reverse=True)

    return jsonify(offers)


@app.route('/api/generate-offer', methods=['POST'])
def generate_offer():
    """Generuje dokument DOCX oferty z progress tracking"""
    import time
    start_time = time.time()

    data = request.json
    form_data = data.get('formData', {})
    selected_products = data.get('selectedProducts', [])
    template_data = data.get('templateData')  # Obs≈Çuga multi-template

    try:
        # Progress: Start
        send_progress("‚öôÔ∏è Rozpoczynam generowanie dokumentu DOCX...", 10)

        # Progress: Tworzenie szablonu
        if template_data and template_data.get('type') == 'multi_file':
            send_progress(f"üìù Przetwarzam szablon {template_data.get('name', 'WolfTax')}...", 20)
        else:
            send_progress("üìù Przetwarzam szablon oferty...", 20)

        # Progress: Dodawanie produkt√≥w
        total_products = len(selected_products)
        if total_products > 0:
            send_progress(f"üì¶ Dodajƒô {total_products} produkt√≥w...", 40)

        output_path, output_filename = generate_offer_docx(data, selected_products, template_data)

        # Progress: Zapisywanie
        send_progress("üíæ Zapisujƒô dokument...", 80)

        # Progress: Gotowe
        elapsed_time = time.time() - start_time
        send_progress(f"‚úÖ Dokument gotowy! ({elapsed_time:.1f}s)", 100)

        # Kr√≥tka pauza aby pokazaƒá 100%
        time.sleep(0.3)

        # Ukryj pasek
        send_progress("", 0)

        return jsonify({
            'success': True,
            'filename': output_filename,
            'download_url': f'/api/download-offer/{output_filename}',
            'generation_time': f"{elapsed_time:.2f}s"
        })
    except Exception as e:
        send_progress(f"‚ùå B≈ÇƒÖd: {str(e)}", 0)
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/download-offer/<filename>')
def download_offer(filename):
    """Pobiera wygenerowanƒÖ ofertƒô"""
    filepath = os.path.join(GENERATED_OFFERS_DIR, filename)

    if not os.path.exists(filepath):
        return jsonify({'error': 'Plik nie istnieje'}), 404

    return send_file(filepath, as_attachment=True, download_name=filename)


@app.route('/api/preview-full-offer', methods=['POST'])
def preview_full_offer():
    """
    Generuje podglƒÖd - INTELIGENTNY CACHE SYSTEM!

    Strategia:
    1. Sprawd≈∫ INTELIGENTNY CACHE (kompletna oferta)
    2. Je≈õli HIT ‚Üí wy≈õlij NATYCHMIAST (<200ms!)
    3. Je≈õli MISS ‚Üí generuj i zapisz do cache
    """
    data = request.json
    template_id = data.get('templateId', 'aidrops')
    template_data = data.get('templateData')
    form_data = data.get('formData', {})
    selected_products = data.get('selectedProducts', [])
    product_custom_fields = data.get('productCustomFields', {})
    use_streaming = data.get('streaming', True)

    print(f"[PREVIEW] Template: {template_id}, Produkty: {selected_products}")

    # ============================================================
    # INTELIGENTNY CACHE - sprawd≈∫ czy ta DOK≈ÅADNA oferta ju≈º istnieje
    # ============================================================
    cache_key = get_offer_cache_key(template_id, form_data, selected_products, product_custom_fields)

    if cache_key and cache_key in offer_cache:
        print(f"[CACHE] üéØ INTELIGENTNY CACHE HIT! Key: {cache_key[:16]}...")
        send_progress("‚ö° ≈Åadujƒô z cache...", 10)

        cached_offer = offer_cache[cache_key]
        pages_metadata = cached_offer['pages']
        total_pages = cached_offer['total_pages']

        print(f"[CACHE] ‚úì Wysy≈Çam {total_pages} stron z cache (INSTANT!)")

        # Wy≈õlij wszystkie strony NATYCHMIAST przez WebSocket
        if use_streaming:
            for page in pages_metadata:
                send_page_ready(page)

        # Usu≈Ñ obrazy z metadanych dla HTTP response (zmniejsz rozmiar)
        metadata_without_images = []
        for meta in pages_metadata:
            meta_copy = {k: v for k, v in meta.items() if k != 'image'}
            meta_copy['has_image'] = True
            metadata_without_images.append(meta_copy)

        send_progress("‚úÖ Gotowe!", 100)

        return jsonify({
            'success': True,
            'total_pages': total_pages,
            'pages_metadata': metadata_without_images,
            'from_cache': True
        })

    # CACHE MISS - generuj normalnie
    print(f"[CACHE] ‚ùå MISS - generujƒô nowƒÖ ofertƒô... Key: {cache_key[:16] if cache_key else 'None'}...")
    send_progress("Generujƒô podglƒÖd...", 5)

    pages_metadata = []
    page_counter = 0

    # Wybierz strategiƒô na podstawie typu szablonu
    if template_data and template_data.get('type') == 'multi_file':
        # NOWY SYSTEM - WolfTax (wiele plik√≥w)
        print("[DEBUG] U≈ºywam multi-file template")
        send_progress("≈Åadujƒô szablon z cache...", 10)

        template_folder = os.path.join(TEMPLATES_DIR, template_data['folder'])
        files = sorted(template_data['files'], key=lambda x: x['order'])
        injection_point = template_data.get('injection_point', {})

        # Procesuj ka≈ºdy plik (ON-DEMAND, bez pre-cache!)
        for file_info in files:
            file_name = file_info['file']
            file_path = os.path.join(template_folder, file_name)

            if not os.path.exists(file_path):
                print(f"[WARNING] Plik nie istnieje: {file_path}")
                continue

            print(f"[PREVIEW] Przetwarzam: {file_name}")
            send_progress(f"üìÑ {file_info.get('name', file_name)}...", 10 + page_counter * 2)

            # Generuj plik (zawsze z aktualnymi danymi)
            # Za≈Çaduj i wype≈Çnij placeholders
            doc = Document(file_path)
            doc = replace_placeholders(doc, form_data)

            # SPIS TRE≈öCI - je≈õli to plik TOC, wygeneruj i wstaw
            if needs_toc:
                toc_config = template_data.get('toc', {})
                start_page = toc_config.get('start_page', 5)

                print(f"[TOC] Generujƒô spis tre≈õci dla {len(selected_products)} produkt√≥w (start: strona {start_page})")
                toc_text = generate_table_of_contents(selected_products, product_custom_fields, start_page)
                doc = inject_toc_into_doc(doc, toc_text)
                print(f"[TOC] Spis tre≈õci wygenerowany:\n{toc_text}")

            # Konwertuj na obrazy
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.docx', dir=PREVIEW_CACHE_DIR)
            doc.save(temp_file.name)
            temp_file.close()

            file_images = convert_docx_to_images(temp_file.name, use_cache=False, progress_callback=None)

            try:
                os.unlink(temp_file.name)
            except:
                pass

            # Wy≈õlij strony tego pliku
            for idx, img_data in enumerate(file_images):
                page_counter += 1
                page_data = {
                    'type': 'template',
                    'number': page_counter,
                    'image': img_data,
                    'has_image': True,
                    'page_index': idx,
                    'status': 'ready',
                    'source_file': file_name
                }
                pages_metadata.append(page_data)

                if use_streaming:
                    send_page_ready(page_data)

            # INJECTION POINT - wstaw produkty po tym pliku
            if (injection_point.get('type') == 'between_files' and
                file_info['file'] == injection_point.get('after')):

                print(f"[DEBUG] Injection point! Wstawiam {len(selected_products)} produkt√≥w po {file_info['file']}")
                send_progress(f"Dodajƒô produkty...", 50)

                # Wstaw produkty w tym miejscu (synchronicznie dla prostoty)
                for product_idx, product_id in enumerate(selected_products):
                    product_path = os.path.join(PRODUKTY_DIR, f'{product_id}.docx')

                    if os.path.exists(product_path):
                        print(f"[DEBUG] Dodajƒô produkt: {product_id}")

                        # Custom fields
                        path_to_convert = product_path
                        temp_file = None

                        if product_id in product_custom_fields and product_custom_fields[product_id]:
                            custom_data = product_custom_fields[product_id]
                            print(f"[CUSTOM FIELDS] Podstawiam dla {product_id}: {custom_data}")

                            product_doc = Document(product_path)
                            product_doc = replace_placeholders(product_doc, custom_data)

                            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.docx', dir=PREVIEW_CACHE_DIR)
                            product_doc.save(temp_file.name)
                            temp_file.close()
                            path_to_convert = temp_file.name

                        # Konwertuj produkt
                        use_cache = (temp_file is None)
                        product_images = convert_docx_to_images(path_to_convert, use_cache=use_cache, progress_callback=None)

                        # Cleanup
                        if temp_file:
                            try:
                                os.unlink(temp_file.name)
                            except:
                                pass

                        # Wy≈õlij strony produktu
                        for idx, img_data in enumerate(product_images):
                            page_counter += 1
                            page_data = {
                                'type': 'product',
                                'number': page_counter,
                                'product_id': product_id,
                                'image': img_data,
                                'has_image': True,
                                'page_index': idx,
                                'status': 'ready'
                            }
                            pages_metadata.append(page_data)

                            if use_streaming:
                                send_page_ready(page_data)

                        print(f"[DEBUG] ‚úì Produkt {product_id} dodany ({len(product_images)} stron)")

    else:
        # AIDROPS (pojedynczy plik) - u≈ºywa INTELIGENTNY CACHE
        print("[DEBUG] U≈ºywam single-file template (AIDROPS)")
        send_progress("Generujƒô szablon...", 10)

        # Generuj szablon z aktualnymi danymi
        template_config = load_template_config('oferta1')
        template_path = os.path.join(TEMPLATES_DIR, template_config['template_file'])

        doc = Document(template_path)
        doc = replace_placeholders(doc, form_data)

        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.docx', dir=PREVIEW_CACHE_DIR)
        doc.save(temp_file.name)
        temp_file.close()

        template_images = convert_docx_to_images(temp_file.name, use_cache=False, progress_callback=send_progress)

        try:
            os.unlink(temp_file.name)
        except:
            pass

        # Wy≈õlij strony szablonu
        for idx, img_data in enumerate(template_images):
            page_counter += 1
            page_data = {
                'type': 'template',
                'number': page_counter,
                'image': img_data,
                'has_image': True,
                'page_index': idx,
                'status': 'ready'
            }
            pages_metadata.append(page_data)

            if use_streaming:
                send_page_ready(page_data)

    send_progress(f"Szablon gotowy ({page_counter} stron)", 40)

    # === PRODUKTY (tylko dla single-file / AIDROPS) ===
    # Dla multi-file produkty sƒÖ ju≈º dodane w injection point powy≈ºej!

    if template_data and template_data.get('type') == 'multi_file':
        # Multi-file - produkty ju≈º dodane w injection point
        print("[DEBUG] Multi-file: produkty ju≈º wstawione w injection point")
        send_progress("Wszystkie strony gotowe!", 100)

        import time
        time.sleep(0.3)
        send_progress("", 0)

        print(f"[DEBUG] Streaming zako≈Ñczony - {len(pages_metadata)} stron")

        # WA≈ªNE: Usu≈Ñ obrazy z metadanych (sƒÖ ju≈º wys≈Çane przez WebSocket!)
        metadata_without_images = []
        for meta in pages_metadata:
            meta_copy = {k: v for k, v in meta.items() if k != 'image'}
            meta_copy['has_image'] = meta.get('status') == 'ready'
            metadata_without_images.append(meta_copy)

        return jsonify({
            'success': True,
            'total_pages': len(pages_metadata),
            'pages_metadata': metadata_without_images
        })

    # === AIDROPS - STARE PRODUKTY Z PARALLEL PROCESSING ===
    total_products = len(selected_products)

    # Najpierw wy≈õlij metadane wszystkich produkt√≥w (wyszarzone)
    for product_idx, product_id in enumerate(selected_products):
        product_path = os.path.join(PRODUKTY_DIR, f'{product_id}.docx')

        if os.path.exists(product_path):
            # Sprawd≈∫ ile stron ma produkt (z cache lub szybkie sprawdzenie)
            file_hash = get_file_hash(product_path)
            if file_hash and file_hash in conversion_cache:
                product_images_count = len(conversion_cache[file_hash])
            else:
                product_images_count = 1  # Domy≈õlnie 1 strona

            for page_idx in range(product_images_count):
                page_counter += 1
                pages_metadata.append({
                    'type': 'product',
                    'number': page_counter,
                    'product_id': product_id,
                    'page_index': page_idx,
                    'status': 'pending'  # Wyszarzona - oczekuje na generowanie
                })

    # PARALLEL PROCESSING: Generuj produkty r√≥wnolegle!
    current_page = page_counter + 1

    def process_product(product_idx, product_id):
        """Przetw√≥rz pojedynczy produkt (thread-safe)"""
        product_path = os.path.join(PRODUKTY_DIR, f'{product_id}.docx')

        if not os.path.exists(product_path):
            return None

        # Wy≈õlij status "generating"
        if use_streaming:
            socketio.emit('product_status', {
                'product_id': product_id,
                'status': 'generating'
            })

        print(f"[PARALLEL] Start konwersji produktu {product_id}")

        # CUSTOM FIELDS: Je≈õli produkt ma custom fields, stw√≥rz tymczasowƒÖ kopiƒô z wype≈Çnionymi warto≈õciami
        path_to_convert = product_path
        temp_file = None

        if product_id in product_custom_fields and product_custom_fields[product_id]:
            custom_data = product_custom_fields[product_id]
            print(f"[CUSTOM FIELDS] Podstawiam dla produktu {product_id}: {custom_data}")

            # Za≈Çaduj produkt i wype≈Çnij placeholders
            product_doc = Document(product_path)
            product_doc = replace_placeholders(product_doc, custom_data)

            # Zapisz do tymczasowego pliku
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.docx', dir=PREVIEW_CACHE_DIR)
            product_doc.save(temp_file.name)
            temp_file.close()
            path_to_convert = temp_file.name

        # Konwertuj (cache dzia≈Ça wewnƒÖtrz funkcji - ale custom fields maja cache wy≈ÇƒÖczony)
        use_cache_for_product = (temp_file is None)  # Cache tylko gdy NIE ma custom fields
        product_images = convert_docx_to_images(path_to_convert, use_cache=use_cache_for_product, progress_callback=None)

        # Usu≈Ñ tymczasowy plik
        if temp_file:
            try:
                os.unlink(temp_file.name)
            except:
                pass

        print(f"[PARALLEL] Zako≈Ñczono konwersjƒô produktu {product_id}: {len(product_images)} stron")

        return {
            'product_id': product_id,
            'product_idx': product_idx,
            'images': product_images
        }

    # U≈ºyj ThreadPoolExecutor do przetwarzania r√≥wnoleg≈Çego (max 3 produkty naraz)
    if len(selected_products) > 0:
        max_workers = min(3, len(selected_products))

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # Uruchom wszystkie produkty r√≥wnolegle
            futures = {
                executor.submit(process_product, idx, pid): pid
                for idx, pid in enumerate(selected_products)
            }

            completed_count = 0

            # Odbieraj wyniki w miarƒô gotowo≈õci
            for future in as_completed(futures):
                product_id = futures[future]

                try:
                    result = future.result()

                    if result:
                        completed_count += 1
                        progress_percent = 30 + int(65 * (completed_count / max(total_products, 1)))
                        send_progress(f"Produkt {completed_count}/{total_products} gotowy...", progress_percent)

                        # STREAMING: Wysy≈Çaj strony przez WebSocket
                        for idx, img_data in enumerate(result['images']):
                            # Oblicz numer strony (produkty mogƒÖ ko≈Ñczyƒá siƒô w r√≥≈ºnej kolejno≈õci!)
                            page_num = current_page + result['product_idx']

                            page_data = {
                                'type': 'product',
                                'number': page_num,
                                'product_id': result['product_id'],
                                'image': img_data,
                                'has_image': True,
                                'page_index': idx,
                                'status': 'ready'
                            }

                            if use_streaming:
                                send_page_ready(page_data)

                        print(f"[PARALLEL] ‚úì Produkt {product_id} wys≈Çany przez WebSocket")

                except Exception as e:
                    print(f"[ERROR] B≈ÇƒÖd przetwarzania produktu {product_id}: {e}")
                    import traceback
                    traceback.print_exc()

    send_progress("Wszystkie strony gotowe!", 100)

    # Daj chwilƒô na wy≈õwietlenie 100%
    import time
    time.sleep(0.3)

    send_progress("", 0)  # Ukryj pasek

    print(f"[DEBUG] Streaming zako≈Ñczony - {len(pages_metadata)} stron")

    # WA≈ªNE: Usu≈Ñ obrazy z metadanych (sƒÖ ju≈º wys≈Çane przez WebSocket!)
    metadata_without_images = []
    for meta in pages_metadata:
        meta_copy = {k: v for k, v in meta.items() if k != 'image'}
        meta_copy['has_image'] = meta.get('status') == 'ready'
        metadata_without_images.append(meta_copy)

    # ============================================================
    # ZAPISZ DO INTELIGENTNEGO CACHE!
    # ============================================================
    if cache_key:
        import time
        offer_cache[cache_key] = {
            'pages': pages_metadata,  # PE≈ÅNE dane z obrazami!
            'total_pages': len(pages_metadata),
            'timestamp': time.time()
        }
        print(f"[CACHE] ‚úì Zapisano do cache: {cache_key[:16]}... ({len(pages_metadata)} stron)")
        print(f"[CACHE] Cache size: {len(offer_cache)} ofert")

    return jsonify({
        'success': True,
        'streaming': use_streaming,
        'pages_metadata': metadata_without_images,
        'total_pages': len(pages_metadata),
        'from_cache': False
    })


@app.route('/api/load-page', methods=['POST'])
def load_single_page():
    """Lazy loading: ≈Çaduje pojedynczƒÖ stronƒô na ≈ºƒÖdanie"""
    data = request.json
    page_type = data.get('type')
    page_index = data.get('page_index')
    product_id = data.get('product_id')
    form_data = data.get('formData', {})

    print(f"[DEBUG] Lazy loading strony: type={page_type}, index={page_index}, product={product_id}")

    try:
        if page_type == 'template':
            # Sprawd≈∫ cache szablonu
            form_hash = get_form_data_hash(form_data)
            if form_hash and form_hash in template_cache:
                template_images = template_cache[form_hash]
                if 0 <= page_index < len(template_images):
                    return jsonify({
                        'success': True,
                        'image': template_images[page_index]
                    })

        elif page_type == 'product' and product_id:
            # Pobierz z cache produktu
            product_path = os.path.join(PRODUKTY_DIR, f'{product_id}.docx')
            if os.path.exists(product_path):
                product_images = convert_docx_to_images(product_path, use_cache=True)
                if 0 <= page_index < len(product_images):
                    return jsonify({
                        'success': True,
                        'image': product_images[page_index]
                    })

        return jsonify({'success': False, 'error': 'Strona nie znaleziona'})

    except Exception as e:
        print(f"[ERROR] B≈ÇƒÖd lazy loading: {e}")
        return jsonify({'success': False, 'error': str(e)})


# WebSocket event handlers
@socketio.on('connect')
def handle_connect():
    print('=' * 80)
    print(f'[WebSocket] ‚úÖ Klient po≈ÇƒÖczony! SID: {request.sid}')
    print('=' * 80)

@socketio.on('disconnect')
def handle_disconnect():
    print(f'[WebSocket] ‚ùå Klient roz≈ÇƒÖczony: {request.sid}')

# ============================================================
# STARTUP: Uruchom unoserver i pre-loading
# ============================================================
print("=" * 80)
print("[STARTUP] üöÄ Inicjalizacja systemu...")
print("=" * 80)

# KROK 1: Uruchom unoserver je≈õli nie dzia≈Ça (tylko na serwerze)
start_unoserver()

# KROK 2: Pre-loading produkt√≥w i szablon√≥w w tle
print("[STARTUP] Uruchamiam pre-loading w tle...")
preload_products_async()
preload_templates_async()

print("[STARTUP] ‚úÖ System gotowy do pracy!")
print("=" * 80)

if __name__ == '__main__':
    socketio.run(app, debug=True, host='0.0.0.0', port=40207, allow_unsafe_werkzeug=True)
